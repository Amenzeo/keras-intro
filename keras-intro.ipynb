{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/title.png\" width=\"95%\"/></center>\n",
    "<center><a href=\"http://bit.ly/pybay-keras\">bit.ly/pybay-keras</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What Do I Do?\n",
    "------\n",
    "\n",
    "<b><center>Professor @</center><b>\n",
    "<center><img src=\"images/msds_logo.png\" width=\"45%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/real_deep_learning.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keras - Neural Networks for humans\n",
    "------\n",
    "\n",
    "<center><img src=\"images/keras-logo-small.jpg\" width=\"20%\"/></center>\n",
    "\n",
    "A high-level, intuitive API for Deep Learning.\n",
    "\n",
    "Easy to define neural networks, then automatically handles execution.\n",
    "\n",
    "A simple, modular interface which allows focus on learning and enables fast experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Goals\n",
    "-----\n",
    "\n",
    "- General introduction to Deep Learning\n",
    "- Overview of Keras library\n",
    "- An end-to-end example in Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Anti-Goals\n",
    "-----\n",
    "\n",
    "- Understanding of Deep Learning\n",
    "- Building neural networks from scratch\n",
    "- A complete survey of keras library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning 101\n",
    "-----\n",
    "<center><img src=\"images/neural_nets.jpg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning (DL) are Neural networks (NN) with >1 hidden layer\n",
    "-------\n",
    "\n",
    "<center><img src=\"images/neural-networks-layers.jpg\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Neural Networks are Nodes & Edges\n",
    "------\n",
    "<center><img src=\"images/sum.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nonlinear function allows learning of nonlinear relationships\n",
    "------\n",
    "\n",
    "<center><img src=\"images/function_3.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Groups of nodes all the way down\n",
    "------\n",
    "\n",
    "<center><img src=\"images/layers.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning isn't magic, it is just very good at finding patterns\n",
    "------\n",
    "\n",
    "<center><img src=\"images/features.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning has fewer steps than traditional Machine Learning\n",
    "------\n",
    "\n",
    "<center><img src=\"images/traditional-ml-deep-learning-2.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want to follow along…\n",
    "-----\n",
    "\n",
    "GitHub repo: [bit.ly/pybay-keras](http://bit.ly/pybay-keras)\n",
    "\n",
    "If you want to type along…\n",
    "------\n",
    "\n",
    "1. Run a local Jupyter Notebook\n",
    "1. [Binder](https://mybinder.org/v2/gh/brianspiering/keras-intro/master): In-Browser Jupyter Notebook\n",
    "1. [Colaboratory](https://colab.research.google.com/): \"Google Docs for Jupyter Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# What is the backend / execution engine?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/tf_logo.jpg\" width=\"70%\"/></center>\n",
    "\n",
    "An open-source software library for Machine Intelligence\n",
    "\n",
    "Numerical computation using data-flow graphs (DFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "TensorFlow: A great backend\n",
    "------\n",
    "A __very__ flexible architecture which allows you to do almost any numerical operation.\n",
    "\n",
    "Then deploy the computation to CPUs or GPUs (one or more) across desktop, cloud, or mobile device. \n",
    "<center><img src=\"images/tf_features.png\" width=\"38%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "MNIST handwritten digit database: <br> The “Hello World!” of Computer Vision\n",
    "------\n",
    "\n",
    "<center><img src=\"images/mnist-digits.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/MNIST-Matrix.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/MNIST_neuralnet_image.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Setup train and test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# protip - visually inspect your data\n",
    "i = randint(0, x_train.shape[0])\n",
    "pyplot.imshow(x_train[i], cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 27_074\n",
    "pyplot.imshow(x_train[i], cmap='gray_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Is this thing a 4 or 9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Munge data\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/mnist_keras.png\" width=\"75%\"/></center>\n",
    "\n",
    "Convert image matrix into vector to feed into first layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Munge Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 784 # 28 x 28\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size) # Transform from matrix to vector\n",
    "x_train = x_train.astype('float32') # Cast as 32 bit integers\n",
    "x_train /= 255 # Normalize inputs from 0-255 to 0.0-1.0\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size) # Transform from matrix to vector\n",
    "x_test = x_test.astype('float32') # Cast as 32 bit integers\n",
    "x_test /= 255 # Normalize inputs from 0-255 to 0.0-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import the most common type of neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define model instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import the most common type of network layer, fully interconnected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "RTFM - https://keras.io/layers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"images/dense.png\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define input layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "layer_input = Dense(units=512,            # Number of nodes\n",
    "                    activation='sigmoid', # The nonlinearity\n",
    "                    input_shape=(image_size,)) \n",
    "model.add(layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define another layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=512, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define output layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "layer_output = Dense(units=10,             # Number of digits (0-9)\n",
    "                     activation='softmax') # Convert neural activation to probability of category\n",
    "\n",
    "model.add(layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Print summary of model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add training paramters to architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Yes - we compile the model to run it\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model to learn weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 17s 312us/step - loss: 2.1620 - acc: 0.3160 - val_loss: 1.9285 - val_acc: 0.4772\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 15s 272us/step - loss: 1.5386 - acc: 0.6498 - val_loss: 1.1031 - val_acc: 0.7738\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 13s 245us/step - loss: 0.9209 - acc: 0.7743 - val_loss: 0.6921 - val_acc: 0.8255\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 15s 284us/step - loss: 0.6692 - acc: 0.8217 - val_loss: 0.5246 - val_acc: 0.8690\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 15s 283us/step - loss: 0.5523 - acc: 0.8482 - val_loss: 0.4430 - val_acc: 0.8845\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(x_train, \n",
    "                     y_train,\n",
    "                     epochs=5, # Number of passes over complete dataset\n",
    "                     verbose=True, \n",
    "                     validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/waiting.jpg\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see how well our model performs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 79us/step\n",
      "Test loss: 0.494\n",
      "Test accuracy: 86.230%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, \n",
    "                                y_test, \n",
    "                                verbose=True)\n",
    "print(f\"Test loss: {loss:.3}\")\n",
    "print(f\"Test accuracy: {accuracy:.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keras' Other Features\n",
    "-----\n",
    "\n",
    "- Common built-in functions (e.g., activation functions and optimitizers)\n",
    "- Convolutional neural network (CNN or ConvNet)\n",
    "- Recurrent neural network (RNN) & Long-short term memory (LSTM)\n",
    "- Pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "-----\n",
    "\n",
    "- Keras is designed for human beings, not computers.\n",
    "- Easier to try out Deep Learning (focus on the __what__, not the __how__).\n",
    "- Simple to define neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/twitter.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Futher Study - Keras\n",
    "--------\n",
    "\n",
    "- [Keras docs](https://keras.io/)\n",
    "- [Keras blog](https://blog.keras.io/)\n",
    "- Keras courses\n",
    "    - [edX](https://www.edx.org/course/deep-learning-fundamentals-with-keras)\n",
    "    - [Coursera](https://www.coursera.org/lecture/ai/keras-overview-7GfN9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Futher Study - Deep Learning\n",
    "--------\n",
    "\n",
    "- Prerequisites: Linear Algebra, Probability, Machine Learning\n",
    "- [fast.ai Course](http://www.fast.ai/)\n",
    "- [Deep Learning Book](http://www.deeplearningbook.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/thank-you-and-any-questions-3.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bonus Material\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Setup train and test splits\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(x_train[randint(0, x_train.shape[0])], cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "\n",
    "# Redefine input dimensions to make sure conv works\n",
    "img_rows, img_cols = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, \n",
    "         kernel_size=(3, 3),\n",
    "         activation='relu',\n",
    "         input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-402-d99bd37e4570>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-402-d99bd37e4570>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    metrics=['accuracy'])\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',a\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 171s 3ms/step - loss: 0.4744 - acc: 0.8259 - val_loss: 0.4301 - val_acc: 0.8398\n"
     ]
    }
   ],
   "source": [
    "# Define training\n",
    "training = model.fit(x_train, \n",
    "                     y_train,\n",
    "                     epochs=1,\n",
    "                     verbose=True, \n",
    "                     validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 826us/step\n",
      "Test loss: 0.448\n",
      "Test accuracy: 83.590%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, \n",
    "                                y_test, \n",
    "                                verbose=True)\n",
    "print(f\"Test loss: {loss:.3}\")\n",
    "print(f\"Test accuracy: {accuracy:.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is `keras`?    \n",
    "-----\n",
    "\n",
    "<center><img src=\"https://www.thevintagenews.com/wp-content/uploads/2017/08/a-drinking-horn-from-the-16th-century-known-as-the-roordahuizum-drinking-horn-on-display-in-the-frisian-museum-at-leeuwarden-640x360.jpg\" width=\"75%\"/></center>\n",
    "\n",
    "Keras (κέρας) means horn in Greek. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is a reference to a literary image from ancient Greek and Latin literature.\n",
    "\n",
    "First found in the Odyssey, where dream spirits (Oneiroi, singular Oneiros) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. \n",
    "\n",
    "It's a play on the words κέρας (horn) / κραίνω (fulfill), and ἐλέφας (ivory) / ἐλεφαίρομαι (deceive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://keras.io/#why-this-name-keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
