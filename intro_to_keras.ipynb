{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/title.png\" width=\"100%\"/></center>\n",
    "<br>\n",
    "<center><a href=\"http://bit.ly/pybay-keras\">bit.ly/pybay-keras</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Who Am I?\n",
    "-----\n",
    "\n",
    "Brian Spiering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"images/msds_logo.png\" width=\"45%\"/></center>\n",
    "\n",
    "Professor at University of San Francisco in the MS in Data Science program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/real_deep_learning.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keras - Neural Networks for humans\n",
    "------\n",
    "\n",
    "<center><img src=\"https://keras.io/img/keras-logo-small.jpg\" width=\"45%\"/></center>\n",
    "\n",
    "A higher-level, more intuitive API for Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Like requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Easy to define neural networks. Then automatically handles execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Like SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A simple and highly modular interface which allows focus on learning and enabling fast experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning 101\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/neural_nets.jpg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning (DL): Neural networks (NN) with >1 hidden layer\n",
    "-------\n",
    "\n",
    "<center><img src=\"http://www.kdnuggets.com/wp-content/uploads/neural-networks-layers.jpg\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Neural networks are groups of nodes\n",
    "------\n",
    "<center><img src=\"http://3.bp.blogspot.com/-7RWgohC4pYE/VhtQ8IELsLI/AAAAAAAAA6I/_XFhMbjpcCY/s1600/Simple%2BNeural%2BNetwork.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/function_3.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://1.bp.blogspot.com/-ZCOvJ9OYHLE/T8jXLkG81XI/AAAAAAAAAto/7LTHWLqOMyg/s1600/p1.png\" height=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning isn't magic, it is just very good at finding patterns.\n",
    "------\n",
    "\n",
    "<center><img src=\"images/features.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning has fewer steps than traditional Machine Learning\n",
    "------\n",
    "\n",
    "<center><img src=\"http://adilmoujahid.com/images/traditional-ml-deep-learning-2.png\" width=\"1500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/twitter.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want to follow along…\n",
    "-----\n",
    "\n",
    "[GitHub repo: bit.ly/pybay-keras](http://bit.ly/pybay-keras)\n",
    "\n",
    "If you want to type along…\n",
    "------\n",
    "1. [Binder: In-Browser Jupyter Notebook](https://mybinder.org/v2/gh/brianspiering/keras-intro/master)\n",
    "2. [Colaboratory: \"Google Docs for Jupyter Notebooks\"](https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/tf_logo.jpg\" width=\"75%\"/></center>\n",
    "\n",
    "\"An open-source software library for Machine Intelligence\"\n",
    "\n",
    "Numerical computation using data flow graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "TensorFlow: A great backend\n",
    "------\n",
    "\n",
    "<center><img src=\"images/tf_features.png\" width=\"75%\"/></center>\n",
    "\n",
    "A __very__ flexible architecture that allows you to do almost any operation.\n",
    "\n",
    "Then deploy computation to CPUs (one or more), GPUs on desktop, cloud, or mobile device. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "MNIST handwritten digit database: <br> The “Hello World!” of Computer Vision\n",
    "------\n",
    "\n",
    "<center><img src=\"images/mnist-digits.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://www.tensorflow.org/versions/r0.10/images/MNIST-Matrix.png\" width=\"800\"/></center>\n",
    "\n",
    "Each pixel is an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/MNIST_neuralnet_image.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Setup train and test splits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(x_train[randint(0, x_train.shape[0])], cmap='gray_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Munge data\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/mnist_keras.png\" width=\"75%\"/></center>\n",
    "\n",
    "Convert image matrix into vector to feed into first layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 784 # 28 x 28\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size) # Transform from matrix to vector\n",
    "x_train = x_train.astype('float32') # Cast as 32 bit integers\n",
    "x_train /= 255 # Normalize inputs from 0-255 to 0.0-1.0\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size) # Transform from matrix to vector\n",
    "x_test = x_test.astype('float32') # Cast as 32 bit integers\n",
    "x_test /= 255 # Normalize inputs from 0-255 to 0.0-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "RTFM - https://keras.io/layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define input layer\n",
    "layer_input = Dense(units=512, \n",
    "                    activation='sigmoid', \n",
    "                    input_shape=(image_size,))\n",
    "model.add(layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define another layer\n",
    "layer_input = Dense(units=512, \n",
    "                    activation='sigmoid')\n",
    "model.add(layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define output layers\n",
    "layer_output = Dense(units=num_classes,\n",
    "                     activation='softmax')\n",
    "\n",
    "model.add(layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 28s 522us/step - loss: 2.1506 - acc: 0.3276 - val_loss: 1.8991 - val_acc: 0.5320\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 26s 480us/step - loss: 1.5085 - acc: 0.6534 - val_loss: 1.0865 - val_acc: 0.8048\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 25s 460us/step - loss: 0.9098 - acc: 0.7790 - val_loss: 0.6828 - val_acc: 0.8453\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 25s 458us/step - loss: 0.6599 - acc: 0.8283 - val_loss: 0.5166 - val_acc: 0.8785\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 32s 589us/step - loss: 0.5443 - acc: 0.8531 - val_loss: 0.4329 - val_acc: 0.8915\n"
     ]
    }
   ],
   "source": [
    "# Define training\n",
    "history = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=5, # Number of passes over complete dataset\n",
    "                    verbose=True, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we wait...\n",
    "------\n",
    "\n",
    "<center><img src=\"images/waiting.jpg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 142us/step\n",
      "Test loss: 0.482\n",
      "Test accuracy: 86.810%\n"
     ]
    }
   ],
   "source": [
    "# Let's see how good we did\n",
    "loss, accuracy = model.evaluate(x_test, \n",
    "                               y_test, \n",
    "                               verbose=True)\n",
    "print(f\"Test loss: {loss:.3}\")\n",
    "print(f\"Test accuracy: {accuracy:.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Other features of Keras\n",
    "-----\n",
    "\n",
    "- Common built-in functions (e.g., activation functions and optimitizers)\n",
    "- Convolutional neural network (CNN, or ConvNet)\n",
    "- Recurrent neural network (RNN) & Long-short term memory (LSTM)\n",
    "- Pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "-----\n",
    "\n",
    "- Keras designed for human beings, not computers.\n",
    "- Simple to define complex neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bonus Material\n",
    "--------"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
